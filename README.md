# ğŸ¤– AI Personality Agent Discord Bot

*A modular, local LLM-powered Discord bot with dynamic personalities and short-term memory.*

---

## ğŸš€ Features

- ğŸ§  **Local Model Integration**  
  Works with local LLMs using Docker (via [Ollama](https://ollama.com/)).

- ğŸ­ **Personality Simulation**  
  Dynamic prompt engineering to simulate multiple AI personas.

- ğŸ’¾ **Short-Term Memory**  
  Maintains contextual awareness with JSON-based memory storage.

- âš™ï¸ **Modular and Extensible**  
  Easily extendable architecture written in Python.


ğŸ§± Architecture Overview
<pre>
 +-------------------------+
|  Python AI Agent Logic  |
+-----------+-------------+
            |
            v
+-------------------------+
|   Memory Engine Layer   |  â† Injects short-term memory context
+-----------+-------------+
            |
            v
+-------------------------+
|   Prompt Engine Layer   |  â† Injects personality into prompt
+-----------+-------------+
            |
            v
+-------------------------+
|   AI Model via Docker   |  â† Local inference (e.g., Ollama)
+-------------------------+

</pre>

## ğŸ“ File Structure
<pre>
.
â”œâ”€â”€ bot.py # Main entry script (Discord bot)
â”œâ”€â”€ cogs/ # Discord command modules
â”‚ â”œâ”€â”€ general.py # Utility commands
â”‚ â””â”€â”€ reply.py # Personality-based replies
â”‚
â”œâ”€â”€ handlers/ # Core functionality
â”‚ â”œâ”€â”€ filehandler.py # File operations (config/logs)
â”‚ â”œâ”€â”€ memory_handler.py # Temporary memory storage
â”‚ â”œâ”€â”€ personalityhandler.py # Personality management
â”‚ â”œâ”€â”€ prompt_builder.py # Structured prompt generation
â”‚ â””â”€â”€ response_handler.py # Response parsing and formatting
â”‚
â”œâ”€â”€ utility/
â”‚ â””â”€â”€ personalities/ # JSON-defined personalities
â”‚ â””â”€â”€ default.json
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .gitignore # Git exclusions
â””â”€â”€ README.md # Youâ€™re here!
</pre>

---

## ğŸ“¦ Requirements

- Python **3.13+**
- Docker **20.10+**
- RAM: **16GB+ recommended**
- Optional: **NVIDIA GPU** for acceleration

### ğŸ”§ Install Dependencies

bash
```pip install -r requirements.txt```

ğŸ³ Local LLM Setup (via Ollama)

Pull the Docker Image
```
docker pull ollama/ollama
```
Run the Container
```
docker run -d --name ollama \
  -p 11434:11434 \
  -v ollama_data:/root/.ollama \
  ollama/ollama
```
Load a Model
```docker exec -it ollama ollama run llama3```
or
```docker exec -it ollama ollama run mistral```

API Access

```Endpoint: http://localhost:11434/api/generate```

(Optional) Enable GPU (Linux + NVIDIA)
```
docker run -d --gpus all \
  --name ollama \
  -p 11434:11434 \
  -v ollama_data:/root/.ollama \
  ollama/ollama
```

âš™ï¸ Configuration
ğŸ”‘ Before First Run

  Replace the token in bot.py with your Discord bot token.

  Update the LLM model name in reply.py with your installed model (e.g., llama3, mistral).

ğŸ­ Personality Profiles

Define custom personalities in utility/personalities/.

Example: default.json
```
{
  "personality": "personality description"
}
```
ğŸ’¬ Bot Commands
| Command        | Description                                                                 |
|----------------|-----------------------------------------------------------------------------|
| `!reply <msg>` | Ask a question or interact with uploaded PDF/DOCX/TXT/PPTX files.           |
| `!commands`    | Lists all available commands.                                               |
| `!forget`      | Clears short-term memory for the server or DM.                              |
| `!chooseTone`  | Opens a menu to select a personality.                                       |
| `!getTone`     | Displays the current active personality.                                    |

ğŸ”„ Personality Switching
    - Shows a paginated menu (5 personalities per page).
    - Only the invoking user can make a selection.
    - Personality persists between sessions.
    - !forget does not reset chosen tone.

ğŸ”® Future Improvements
    - âœ… Persistent personality storage via database
    - âœ… Voice chat support with text-to-speech and transcription
    - âœ… Export responses as .txt or .md files

ğŸ“£ Contributions

Contributions are welcome! Fork, modify, and send a pull request.
